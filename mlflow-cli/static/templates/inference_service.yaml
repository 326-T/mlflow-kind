apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: "{{ inference_service_name }}"
  namespace: "{{ namespace }}"
spec:
  predictor:
    serviceAccountName: s3-inference-sa
    containers:
      - name: kserve-container
        image: 326takeda/kserve-sentence-transformer:latest
        env:
          - name: STORAGE_URI
            value: s3://{{ bucket_name }}/{{ experiment_id }}/{{ run_id }}/artifacts/{{ model_name }}
          - name: APP_ARGS
            value: "--model_name {{ model_name }} --predictor_protocol v2"
